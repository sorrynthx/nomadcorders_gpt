{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain.chat_models에서 ChatOpenAI를 가져옴\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# ChatOpenAI의 인스턴스를 생성하고, 낮은 온도 설정으로 대화의 예측 가능성을 높임\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\",\n",
    ")\n",
    "\n",
    "prompt = template.format(country_a=\"South Korea\", country_b=\"Japan\")\n",
    "\n",
    "#chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain.schema에서 여러 메시지 타입을 가져옴\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# 대화 메시지의 시퀀스를 정의함\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    # 시스템 메시지는 지리 전문가로서, 오직 {language}로만 답변하라는 지시를 포함함\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    # AI 메시지는 자기 소개를 함\n",
    "    (\"ai\", \"Hi my name is {name}!\"),\n",
    "    # 인간 메시지는 {country_a}와 {country_b} 사이의 거리를 묻고, AI의 이름을 물음\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}. Also what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"Japan\",\n",
    "    name=\"Haru\",\n",
    "    country_a=\"Japan\",\n",
    "    country_b=\"South Korea\",\n",
    ")\n",
    "\n",
    "#chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'How', 'Are', 'you']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello, How, Are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charizard', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with comma seperated list of max {max_items} in lowercase. DO NOT reply with anything else\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\": 5,\n",
    "    \"question\": \"What are the poketmons ?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 정리\n",
    "### langchain\n",
    "Prompt Template 만들고, OutputParser 처리, langchain invoke 사용 (파이프라인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain.chat_models에서 ChatOpenAI를 가져오기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 예측 가능한 대화를 위해 낮은 온도 설정으로 ChatOpenAI 인스턴스 생성\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# 단순 거리 질의에 대한 템플릿 생성\n",
    "# 두 나라 간의 거리에 관한 템플릿을 생성합니다.\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\",\n",
    ")\n",
    "\n",
    "# 템플릿 포매팅을 사용하여 특정 국가 쌍에 대한 질문 생성\n",
    "prompt = template.format(country_a=\"South Korea\", country_b=\"Japan\")\n",
    "\n",
    "# chat.predict(prompt) # 이 코드는 실행되지 않았으므로 주석 처리합니다.\n",
    "\n",
    "### =============================================================== ###\n",
    "\n",
    "# langchain.schema에서 필요한 메시지 타입 가져오기\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# 대화 흐름을 정의하는 템플릿 생성\n",
    "# 지리 전문가로서의 역할과 답변 언어를 지정하는 시스템 메시지를 포함합니다.\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Hi my name is {name}!\"),\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}. Also what is your name?\")\n",
    "])\n",
    "\n",
    "# 대화 흐름을 포매팅하여 실제 값을 채워 넣습니다.\n",
    "prompt = template.format_messages(\n",
    "    language=\"Korean\", # 언어를 일본어에서 한국어로 변경했습니다.\n",
    "    name=\"Haru\",\n",
    "    country_a=\"Japan\",\n",
    "    country_b=\"South Korea\",\n",
    ")\n",
    "\n",
    "# chat.predict_messages(prompt) # 이 코드는 실행되지 않았으므로 주석 처리합니다.\n",
    "\n",
    "### =============================================================== ###\n",
    "\n",
    "# 출력 파싱을 위한 클래스 정의\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    # 컴마로 구분된 문자열을 리스트로 변환\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "# CommaOutputParser 인스턴스 생성\n",
    "p = CommaOutputParser()\n",
    "\n",
    "# 파서를 테스트하기 위한 문자열 파싱\n",
    "p.parse(\"Hello, How, Are, you\")\n",
    "\n",
    "### =============================================================== ###\n",
    "\n",
    "\n",
    "# 리스트 생성기로서의 역할을 정의하는 대화 흐름 생성\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with comma separated list of max {max_items} items in lowercase. DO NOT reply with anything else\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 파이프라인을 구성하여 대화 템플릿, 챗봇, 그리고 출력 파서를 연결합니다.\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "# 파이프라인을 호출하여 질문에 대한 답변을 리스트 형태로 변환합니다.\n",
    "chain.invoke({\n",
    "    \"max_items\": 5,\n",
    "    \"question\": \"What are the Pokémon?\" # 'poketmons' 오타를 'Pokémon'으로 수정했습니다.\n",
    "}) \n",
    "# 결과: ['pikachu', 'charizard', 'bulbasaur', 'squirtle', 'jigglypuff']\n",
    "\n",
    "# CommaOutputParser 클래스는 BaseOutputParser를 상속받아 구현되었습니다.\n",
    "# 이 클래스는 입력된 텍스트를 쉼표로 분리하여 리스트로 만드는 역할을 합니다.\n",
    "# 이 과정은 데이터 처리나 문자열 파싱에 유용할 수 있습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
